configuration:
  batch_size: 64
  optimizer: torch.optim.AdamW

  lr: 0.001

  trainer: experiment_setup.train_loop
  scorer: experiment_setup.score
  model: models.clipseg.CLIPDensePredT

  lr_scheduler: cosine
  T_max: 20000
  eta_min: 0.0001

  max_iterations: 20000
  val_interval: 1000

  # dataset
  dataset: datasets.AGCLoader.ArgiculturalDataset
  # split_mode: pascal_test
  split: train
  mask: text_and_blur3_highlight01
  image_size: 352
  normalize: True
  pre_crop_image_size: [sample, 1, 1.5]

  # general
  mix: True
  prompt: shuffle+
  norm_cond: True
  mix_text_min: 0.0
  
  # model
  out: 1
  extract_layers: [3, 7, 9]
  reduce_dim: 64
  depth: 3
  fix_shift: False

  loss: custom.DiceLoss.DiceLoss
  #torch.nn.functional.binary_cross_entropy_with_logits
  amp: True

test_configuration_common:
  normalize: True
  image_size: 352
  # max_iterations: 10
  batch_size: 8
  sigmoid: True
  test_dataset: agc
  metric: metrics.FixedIntervalMetrics

test_configuration: 
  -
    name: coco_h
    mask: blur3_highlight01

columns: [i, name,
coco_t_fgiou_best, coco_t_miou_best,  coco_t_fgiou_0.5, 
coco_h_fgiou_best, coco_h_miou_best,  coco_h_fgiou_0.5,
coco_h2_fgiou_best, coco_h2_miou_best,  coco_h2_fgiou_0.5, coco_h2_fgiou_best_t,
train_loss, duration, date
]

individual_configurations:
- {name: rd64-agc, version: 'ViT-B/16', fold: 0, reduce_dim: 64, mask: text_and_crop_blur_highlight352, T_max: 7000, max_iterations: 7000}